<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Dai Zhongxiang</title>
  
  <meta name="author" content="Dai Zhongxiang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Dai Zhongxiang</name>
              </p>
              <p>
              	I will join <a href="https://www.cuhk.edu.cn/en">Chinese University of Hong Kong, Shenzhen (CUHKSZ)</a>, <a href="https://sds.cuhk.edu.cn/en">School of Data Science</a> as an Assistant Professor in Aug 2024!
              	I'll be looking for PhD students, RAs, postdocs and visiting students. Feel free to reach out if you're interested in working with me. [School Webpage: <a href="https://sds.cuhk.edu.cn/en/teacher/1746">Zhongxiang Dai</a>].
              </p>
<!--               <p>
              	I'll join 
              	 as a  starting Jan 1, 2024.
              </p> -->
              <p>
              	I'm currently a Postdoctoral Associate in MIT <a href="https://lids.mit.edu">Laboratory for Information and Decision Systems (LIDS)</a>, advised by Prof. <a href="http://web.mit.edu/jaillet/www/">Patrick Jaillet</a>. 
              	Previously, I was a Research Fellow in Department of Computer Science, National University of Singapore, advised by Assoc. Prof. <a href="https://www.comp.nus.edu.sg/~lowkh/index.html">Bryan Kian Hsiang Low</a>.
              </p>
              <p>
 								I work on AI and machine learning. My main research interests include <b>Bayesian optimization</b> (BO) and <b>multi-armed bandits</b> (MAB), as well as other related areas such as active learning and reinforcement learning.
 								The goal of my research is to
 								<blockquote style="font-size: 16px">
 								<b>develop novel BO and MAB algorithms to <span style="color:#CD5C5C">solve complex real-world optimization problems (e.g., AutoML and AI4Science problems)</span> <span style="color:#228B22">in a theoretically principled manner (e.g., via regret analysis)</span></b>.
 							</blockquote>
              </p>
              

              <p style="text-align:center">
                <a href="mailto:zhongxiangdaiai@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=1v8xOIYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/Dai_Zh">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/daizhongxiang">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/icml_2023_at_hawaii.jpeg"><img style="width:93%;max-width:93%" alt="profile photo" src="images/icml_2023_at_hawaii.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>My Research</heading>
			  <ul>

<!-- <p>
	Below is a summary of my past research. Please see my list of publications below for more details.
</p>
<p>
              <a href="images/works_dzx.png"><img style="width:60%;max-width:60%" alt="summary of my works" src="images/works_dzx.png" class="hoverZoomLink"></a>
</p>
 -->
<p style="font-size: 16px">
<!-- My future research plans include: -->
				<li style="font-size: 16px">
				<b><span style="color:#CD5C5C">Automating advanced AI algorithms</span></b> such as large language models (LLMs)
   			</li>
				<ul>
				<li style="font-size: 16px">
				Example: automatically optimizing the prompt for LLMs using bandits (<a href="https://arxiv.org/abs/2310.02905">Automated Prompting</a>)
				</li>
			  </ul>
				<li style="font-size: 16px">
				<b><span style="color:#CD5C5C">AI4Science</span></b>: solving complex optimization problems in different areas of science
				</li>
				<li style="font-size: 16px">
				<b><span style="color:#228B22">Fundamental theoretical problems</span></b> in Bayesian optimization and multi-armed bandits
				</li>
</p>
            </td>
          </tr>
        </tbody></table>		

		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>What's New</heading>
			  <ul>
				<li>
				<p>
				May 2024: Our paper on automated prompting accepted to ICML 2024!
				</p>
				</li>
				<li>
				<p>
				Apr 2024: I'll join CUHKSZ, School of Data Science as an Assistant Professor!
				</p>
				</li>
				<li>
				<p>
				Mar 2024: Our 2 contributed chapters to the book <a href="https://www.sciencedirect.com/book/9780443190377/federated-learning">Federated Learning: Theory and Practice</a> are online!
				</p>
				</li>
				<li>
				<p>
				Jan 2024: Our paper on NAS accepted to ICLR 2024!
				</p>
				</li>
				<li>
				<p>
				Oct 2023: Check out our 2 pre-prints on LLM about <a href="https://arxiv.org/abs/2310.02905">Automated Prompting</a> and <a href="https://arxiv.org/abs/2310.00646">Watermarking</a>!
				</p>
				</li>
				<li>
				<p>
				Sep 2023: 3 papers accepted to NeurIPS 2023!
				</p>
				</li>
<!-- 				<li>
				<p>
				Apr 2023: Our paper on Neural Active Learning accepted to ICML 2023!
				</p>
				</li>
				<li>
				<p>
				Apr 2023: Gave a presentation at <a href="https://ncript.comp.nus.edu.sg/site/ncript-workshop-2023/">N-CRiPT Technical Workshop</a> about our work on Differentially Private Federated Bayesian Optimization
				</p>
				</li>
				<li>
				<p>
				Mar 2023: Invited to serve as a reviewer for NeurIPS 2023
				</p>
				</li>
				<li>
				<p>
				Jan 2023: 2 papers accepted to ICLR 2023!
				</p>
				</li> -->
<!-- 				<li>
				<p>
				Dec 2022: Invited to serve as a reviewer for ICML 2023 and UAI 2023
				</p>
				</li> -->
<!-- 				<li>
				<p>
				Dec 2022: Our paper on Recursive Reasoning-Based Training-Time Adversarial ML accepted to the AI Journal!
				</p>
				</li> -->
<!-- 				<li>
				<p>
				Sep 2022: 2 papers accepted to NeurIPS 2022!
				</p>
				</li> -->
<!-- 				<li>
				<p>
				Aug 2022: Invited to serve as a reviewer for AAMAS 2023
				</p>
				</li>			  	
				<li>
				<p>
				Aug 2022: Invited to serve as a reviewer for AAAI 2023
				</p>
				</li>			  	
				<li>
				<p>
				Jul 2022: Invited to serve as a reviewer for ICLR 2023
				</p>
				</li>			  	
				<li>
				<p>
				Jul 2022: Invited to serve as a reviewer for CoRL 2022
				</p>
				</li>
				<li>
				<p>
				May 2022: Our papers on "Meta-Bayesian Optimization" and "Neural Ensemble Search" are accepted to UAI 2022!
				</p>
				</li>
				<li>
				<p>
				May 2022: Our paper "Bayesian Optimization under Stochastic Delayed Feedback" accepted to ICML 2022!
				</p>
				</li>
				<li>
				<p>
				Mar 2022: Invited to serve as a reviewer for NeurIPS 2022
				</p>
				</li>
				<li>
				<p>
				Feb 2022: Invited to serve as a reviewer for Transactions on Machine Learning Research (TMLR)
				</p>
				</li>
				<li>
				<p>
				Jan 2022: Our <a href="https://openreview.net/forum?id=v-v1cpNNK_v">paper on NAS at Initialization</a> accepted to ICLR 2022!
				</p>
				</li> -->
<!--
				<li>
				<p>
				Nov 2021: Invited to serve as a Senior Program Committee member for ICML 2022!
				</p>
				</li>
				<li>
				<p>
				Sep 2021: Three papers accepted to NeurIPS 2021!
				</p>
				</li>
				<li>
				<p>
				Sep 2021: Invited to serve as a reviewer for IEEE RA-L and ICRA 2022
				</p>
				</li>
				<li>
				<p>
				Aug 2021: Won <b>Dean's Graduate Research Excellence Award</b>!
				</p>
				</li>
-->
<!--
				<li>
				<p>
				Aug 2021: Invited to serve as a Program Committee member for AAAI 2022
				</p>
				</li>
				<li>
				<p>
				Jul 2021: Invited to serve as a Program Committee member for <a href="https://neurips2021workshopfl.github.io/NFFL-2021/">NeurIPS 2021 Workshop on Federated Learning</a>
				</p>
				</li>
				<li>
				<p>
				Jul 2021: Invited to serve as a Program Committee Board member for IJCAI 2022-2024 (PC member for 3 years)
				</p>
				</li>
				<li>
				<p>
				Jul 2021: Invited to serve as a reviewer for CVPR 2022
				</p>
				</li>
				<li>
				<p>
				Jun 2021: Defended my thesis titled <b>Sample-Efficient Automated Machine Learning with Bayesian Optimization</b>! <br>
				</p>
				</li>
-->
<!--				
				<li>
				<p>
				Jun 2021: Invited to serve as a reviewer for ICLR 2022
				</p>
				</li>
-->
			  </ul>
            </td>
          </tr>
        </tbody></table>		


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Education</heading>
	<ul>
		<p>
		<li>
		National University of Singapore (NUS) &nbsp (<i>Aug 2017 - Apr 2021</i>)
		<ul>
			<li>
			Ph.D. student in Artificial Intelligence, Department of Computer Science
			</li>
			<li>
			Advisors: <a href="https://www.comp.nus.edu.sg/~lowkh/index.html">Bryan Kian Hsiang Low</a> (NUS) & 
			<a href="http://web.mit.edu/jaillet/www/">Patrick Jaillet</a> (MIT)
			</li>
<!-- 			<li>
			Thesis: <a href="https://daizhongxiang.github.io/papers/thesis.pdf">Sample-Efficient Automated Machine Learning with Bayesian Optimization</a>
			</li> -->
			<li>
			Supported by Singapore-MIT Alliance for Research and Technology (SMART) Graduate Fellowship,
			eligible for co-supervision by an MIT faculty and research residency at MIT for up to six months
			</li>
		</ul>		
		</li>
		</p>
		
		<p>
		<li>
		National University of Singapore (NUS) &nbsp (<i>Aug 2011 - Jun 2015</i>)
		<ul>
			<li>
			Bachelor of Engineering (Electrical Engineering), First Class Honors
			</li>
		</ul>
		</li>
		</p>
	</ul>
            </td>
          </tr>
        </tbody></table>		




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Book Chapters</heading>
  <br>
  * denotes equal contribution. <br>

	<ul>
		<li>
		<p>
		<a href="https://www.sciencedirect.com/science/article/abs/pii/B9780443190377000235">Federated sequential decision making: Bayesian optimization, reinforcement learning, and beyond.</a> <br>
		<b>Zhongxiang Dai</b>*, Flint Xiaofeng Fan*, Cheston Tan, Trong Nghia Hoang, Kian Hsiang Low and Patrick Jaillet. <br>
		<a href="https://www.sciencedirect.com/book/9780443190377/federated-learning">Federated Learning: Theory and Practice</a>, Chapter 14, pages 257-279, Academic Press, 2024.<br> 
		</p>
		</li>

		<li>
		<p>
		<a href="https://www.sciencedirect.com/science/article/abs/pii/B9780443190377000247">Data valuation in federated learning.</a> <br>
		Zhaoxuan Wu, Xinyi Xu, Rachael Hwee Ling Sim, Yao Shu, Xiaoqiang Lin, Lucas Agussurja, <b>Zhongxiang Dai</b>, See-Kiong Ng, Chuan-Sheng Foo, Patrick Jaillet, Trong Nghia Hoang and Kian Hsiang Low. <br>
		<a href="https://www.sciencedirect.com/book/9780443190377/federated-learning">Federated Learning: Theory and Practice</a>, Chapter 15, pages 281-296, Academic Press, 2024.<br> 
		</p>
		</li>

		</p>
		</li>
	</ul>
            </td>
			</tr>
        </tbody></table>		




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Workshop Papers & Pre-prints</heading>
  <br>
  * denotes equal contribution, <span>&#8224;</span> denotes corresponding author. <br>

	<ol>

		<li>
		<p>
		<a href="https://arxiv.org/abs/2405.17346">Prompt Optimization with Human Feedback.</a> <br>
		Xiaoqiang Lin, <b>Zhongxiang Dai</b><span>&#8224;</span>, Arun Verma, See-Kiong Ng, Patrick Jaillet and Kian Hsiang Low. <br>
		ICML 2024, Workshop on Models of Human Feedback for AI Alignment. [<a href="https://arxiv.org/abs/2405.17346">arXiv</a>]<br>
		<span style="color:#9F000F">Selected as Oral</span>
		</p>
		</li>


		<li>
		<p>
		<a href="https://openreview.net/forum?id=Hh0b1HlrZJ">Neural Dueling Bandits.</a> <br>
		Arun Verma*, <b>Zhongxiang Dai</b>*<span>&#8224;</span>, Xiaoqiang Lin, Patrick Jaillet and Kian Hsiang Low. <br>
		ICML 2024, Workshop on Foundations of Reinforcement Learning and Control -- Connections and Perspectives. <br>
		<!-- [<a href="https://arxiv.org/abs/2405.17346">arXiv</a>] -->
		</p>
		</li>


		<li>
		<p>
		<a href="https://arxiv.org/abs/2405.16122">Prompt Optimization with EASE? Efficient Ordering-aware Automated Selection of Exemplars.</a> <br>
		Zhaoxuan Wu*, Xiaoqiang Lin*, <b>Zhongxiang Dai</b>, Wenyang Hu, Yao Shu, See-Kiong Ng, Patrick Jaillet and Kian Hsiang Low. <br> 
		ICML 2024, Workshop on In-Context Learning. [<a href="https://arxiv.org/abs/2405.16122">arXiv</a>]
		<!-- Pre-print, 2024 <br>  -->
		</p>
		</li>

		<li>
		<p>
		<a href="https://arxiv.org/abs/2403.02993">Localized Zeroth-Order Prompt Optimization.</a> <br>
		Wenyang Hu, Yao Shu, Zongmin Yu, Zhaoxuan Wu, Xiaoqiang Lin, <b>Zhongxiang Dai</b>, See-Kiong Ng and Kian Hsiang Low. <br>
		ICML 2024, Workshop on In-Context Learning. [<a href="https://arxiv.org/abs/2403.02993">arXiv</a>]
		<!-- Pre-print, 2024 <br>  -->
		</p>
		</li>

		<li>
		<p>
		<a href="https://arxiv.org/abs/2406.14473">Data-Centric AI in the Age of Large Language Models.</a> <br>
		Xinyi Xu, Zhaoxuan Wu, Rui Qiao, Arun Verma, Yao Shu, Jingtan Wang, Xinyuan Niu, Zhenfeng He, Jiangwei Chen, Zijian Zhou, Gregory Kang Ruey Lau, Hieu Dao, Lucas Agussurja, Rachael Hwee Ling Sim, Xiaoqiang Lin, Wenyang Hu, <b>Zhongxiang Dai</b>, Pang Wei Koh, Kian Hsiang Low. <br>
		Pre-print, 2024. [<a href="https://arxiv.org/abs/2406.14473">arXiv</a>]
		</p>
		</li>

<!-- 		<li>
		<p>
		<a href="https://arxiv.org/abs/2310.02905">Use Your INSTINCT: INSTruction optimization usIng Neural bandits Coupled with Transformers.</a> <br>
		Xiaoqiang Lin*, Zhaoxuan Wu*, <b>Zhongxiang Dai</b><span>&#8224;</span>, Wenyang Hu, Yao Shu, See-Kiong Ng, Patrick Jaillet and Kian Hsiang Low. <br> 
		NeurIPS 2023, Workshop on Instruction Tuning and Instruction Following <br> 
		[<a href="https://xqlin98.github.io/INSTINCT/">Project page</a>, <a href="https://github.com/xqlin98/INSTINCT">Code</a>, <a href="https://arxiv.org/abs/2310.02905">arXiv</a>] <br> 
		<span style="color:#9F000F"><i>Key Words:</i></span> LLM, neural bandits, automated prompting, prompt optimization.
		</p>
		</li> -->

		<li>
		<p>
		<a href="https://arxiv.org/abs/2310.00646">WASA: WAtermark-based Source Attribution for Large Language Model-Generated Data.</a> <br>
		Jingtan Wang*, Xinyang Lu*, Zitong Zhao*, <b>Zhongxiang Dai</b>, Chuan-Sheng Foo, See-Kiong Ng and Kian Hsiang Low <br> 
		Pre-print, 2023. [<a href="https://arxiv.org/abs/2310.00646">arXiv</a>] <br> 
		<!-- <span style="color:#9F000F"><i>Key Words:</i></span> LLM, watermarking, source attribution, data provenance. -->
		</p>
		</li>

		<li>
		<p>
		<a href="https://arxiv.org/abs/2308.04077">Federated Zeroth-Order Optimization using Trajectory-Informed Surrogate Gradients.</a> <br>
		Yao Shu, Xiaoqiang Lin, <b>Zhongxiang Dai</b><span>&#8224;</span> and Kian Hsiang Low <br> 
		ICML 2024, Workshop on Differentiable Almost Everything: Differentiable Relaxations, Algorithms, Operators, and Simulators. [<a href="https://arxiv.org/abs/2308.04077">arXiv</a>]
		<!-- Pre-print, 2023 <br>  -->
		</p>
		</li>

<!-- 		<li>
		<p>
		<a href="https://arxiv.org/abs/2301.11135">FedHQL: Federated Heterogeneous Q-Learning.</a> <br>
		Flint Xiaofeng Fan, Yining Ma, <b>Zhongxiang Dai</b>, Cheston Tan, Kian Hsiang Low and Roger Wattenhofer <br> 
		Pre-print, 2023 [<a href="https://arxiv.org/abs/2301.11135">arXiv</a>] <br> 
		</p>
		</li>
 -->
		<li>
		<p>
		<a href="https://arxiv.org/abs/2205.04901">Adjusted Expected Improvement for Cumulative Regret Minimization in Noisy Bayesian Optimization.</a> <br>
		Shouri Hu, Haowei Wang, <b>Zhongxiang Dai</b>, Kian Hsiang Low and Szu Hui Ng. <br> 
		Pre-print, 2022 [<a href="https://arxiv.org/abs/2205.04901">arXiv</a>] <br> 
		<!-- <span style="color:#9F000F"><i>Key Words:</i></span> training-free neural architecture search, neural tangent kernel. -->
		</p>
		</li>


<!--
		<li>
		<p>
		<a href="https://arxiv.org/abs/2201.09785">Unifying and Boosting Gradient-Based Training-Free Neural Architecture Search.</a> <br>
		Yao Shu, <b>Zhongxiang Dai</b>, Zhaoxuan Wu and Kian Hsiang Low. <br> 
		Pre-print, 2021 [<a href="https://arxiv.org/abs/2201.09785">arXiv</a>] <br> 
-->
<!--
		<span style="color:#9F000F"><i>Key Words:</i></span> training-free neural architecture search, neural tangent kernel.
-->
		</p>
		</li>
<!--
		<li>
		<p>
		<a href="https://arxiv.org/abs/2109.02533">Going Beyond Neural Architecture Search with Sampling-based Neural Ensemble Search.</a> <br>
		Yao Shu, Yizhou Chen, <b>Zhongxiang Dai</b> and Kian Hsiang Low. <br> 
		Pre-print, 2021 [<a href="https://arxiv.org/abs/2109.02533">arXiv</a>] <br> 
		<span style="color:#9F000F"><i>Key Words:</i></span> neural ensemble search, neural architecture search.
		</p>
		</li>
-->
	</ol>
            </td>
			</tr>
        </tbody></table>		



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
  <br>
  * denotes equal contribution, <span>&#8224;</span> denotes corresponding author. <br>
<!--	<h3>
	2023
	</h3>
-->
	<ol>
		<li>
		<p>
		<a href="https://arxiv.org/abs/2310.02905">Use Your INSTINCT: INSTruction optimization usIng Neural bandits Coupled with Transformers.</a> <br>
		Xiaoqiang Lin*, Zhaoxuan Wu*, <b>Zhongxiang Dai</b><span>&#8224;</span>, Wenyang Hu, Yao Shu, See-Kiong Ng, Patrick Jaillet and Kian Hsiang Low. <br>
		<i>ICML 2024</i>. Acceptance rate: 27.5%. <br>
		[<a href="https://xqlin98.github.io/INSTINCT/">Project page</a>, <a href="https://github.com/xqlin98/INSTINCT">Code</a>, <a href="https://arxiv.org/abs/2310.02905">arXiv</a>] <br>
		Also presented at NeurIPS 2023, Workshop on Instruction Tuning and Instruction Following <br> 
		</p>
		</li>
		<li>
		<p>
		<a href="https://arxiv.org/abs/2403.07591">Robustifying and Boosting Training-Free Neural Architecture Search.</a> <br>
		Zhenfeng He, Yao Shu, <b>Zhongxiang Dai</b>, Bryan Kian Hsiang Low. <br>
		<i>ICLR 2024</i>. Acceptance rate: 31%. <br>
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/quantum_bo.pdf">Quantum Bayesian Optimization.</a> <br>
		<b>Zhongxiang Dai</b>*, Gregory Kang Ruey Lau*, Arun Verma, Yao Shu, Kian Hsiang Low and Patrick Jaillet. <br>
		<i>NeurIPS 2023</i>. Acceptance rate: 26.1%. [<a href="https://github.com/daizhongxiang/Quantum_Bayesian_Optimization">code</a>] <br>
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/batch_bo_replicable.pdf">Batch Bayesian Optimization For Replicable Experimental Design.</a> <br>
		<b>Zhongxiang Dai</b>, Quoc Phong Nguyen, Sebastian Shenghong Tay, Daisuke Urano, Richalynn Leong, Kian Hsiang Low and Patrick Jaillet. <br>
		<i>NeurIPS 2023</i>. Acceptance rate: 26.1%. <br>
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/bandit_aux_feedback.pdf">Exploiting Correlated Auxiliary Feedback in Parameterized Bandits.</a> <br>
		Arun Verma, <b>Zhongxiang Dai</b>, Yao Shu and Kian Hsiang Low. <br>
		<i>NeurIPS 2023</i>. Acceptance rate: 26.1%. <br>
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/neural_active_learning.pdf">Training-Free Neural Active Learning with Initialization-Robustness Guarantees.</a> <br>
		Apivich Hemachandra, <b>Zhongxiang Dai</b><span>&#8224;</span>,  Jasraj Singh, See-Kiong Ng and Kian Hsiang Low. <br>
		<i>ICML 2023</i>. Acceptance rate: 27.9%. <br>
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/fed_neural_bandits.pdf">Federated Neural Bandits.</a> <br>
		<b>Zhongxiang Dai</b>, Yao Shu, Arun Verma, Flint Xiaofeng Fan, Kian Hsiang Low and Patrick Jaillet. <br>
<!--		In <i>11th International Conference on Learning Representations (<b>ICLR-23</b>)</i>, May 1-5, 2023. <br>
-->
		<i>ICLR 2023</i>. Acceptance rate: 31.8%. <br>
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/zoo.pdf">Zeroth-Order Optimization with Trajectory-Informed Derivative Estimation.</a> <br>
		Yao Shu*, <b>Zhongxiang Dai</b>*, Weicong Sng, Arun Verma, Patrick Jaillet and Kian Hsiang Low. <br>
<!--		In <i>11th International Conference on Learning Representations (<b>ICLR-23</b>)</i>, May 1-5, 2023. <br>
-->
		<i>ICLR 2023</i>. Acceptance rate: 31.8%. <br>
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/aij2023.pdf">Recursive Reasoning-Based Training-Time Adversarial Machine Learning.</a> <br>
		Yizhou Chen, <b>Zhongxiang Dai</b>, Haibin Yu, Kian Hsiang Low and Teck-Hua Ho. <br>
		In <i>Artificial Intelligence</i> (Special Issue on Risk-Aware Autonomous Systems: Theory and Practice), 2023. <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> Recursive reasoning, adversarial machine learning, game theory.
-->
		</p>
		</li>
<!--	</ul>
<h3>
	2022
	</h3>
	<ul>
-->
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/sto_bnts.pdf">Sample-Then-Optimize Batch Neural Thompson Sampling.</a> <br>
		<b>Zhongxiang Dai</b>, Yao Shu, Kian Hsiang Low and Patrick Jaillet. <br>
<!--		In <i>36th Conference on Neural Information Processing Systems (<b>NeurIPS-22</b>)</i>, Nov 28-Dec 9, 2022. <br>
-->
		<i>NeurIPS 2022</i>. Acceptance rate: 25.6%. [<a href="https://arxiv.org/abs/2210.06850">arXiv</a>, <a href="https://github.com/daizhongxiang/sto-bnts">Code</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> Neural bandits, neural tangent kernel, Bayesian optimization.
-->
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/hnas.pdf">Unifying and Boosting Gradient-Based Training-Free Neural Architecture Search.</a> <br>
		Yao Shu, <b>Zhongxiang Dai</b><span>&#8224;</span>, Zhaoxuan Wu and Kian Hsiang Low. <br>
<!--		In <i>36th Conference on Neural Information Processing Systems (<b>NeurIPS-22</b>)</i>, Nov 28-Dec 9, 2022. <br>
-->
		<i>NeurIPS 2022</i>. Acceptance rate: 25.6%. [<a href="https://arxiv.org/abs/2201.09785">arXiv</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> Neural architecture search, neural tangent kernel, Bayesian optimization.
-->
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/bo_sdf.pdf">Bayesian Optimization under Stochastic Delayed Feedback.</a> <br>
		Arun Verma*, <b>Zhongxiang Dai</b>* and Kian Hsiang Low. <br>
<!--		In <i>39th International Conference on Machine Learning (<b>ICML-22</b>) </i>  <br> 
-->
		<i>ICML 2022</i>. Acceptance rate: 21.9%. <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> Bayesian optimization, delayed feedback, batch Bayesian optimization.
-->
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/meta-BO.pdf">On Provably Robust Meta-Bayesian Optimization.</a> <br>
		<b>Zhongxiang Dai</b>, Yizhou Chen, Haibin Yu, Kian Hsiang Low and Patrick Jaillet. <br>
<!--		In <i>38th Conference on Uncertainty in Artificial Intelligence (<b>UAI-22</b>) </i>  <br> 
-->
		<i>UAI 2022</i>. Acceptance rate: 32.3%. [<a href="https://openreview.net/forum?id=BYIz5IIiql9">OpenReview</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> Bayesian optimization, meta-learning.
-->
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/neural_ensemble_search.pdf">Neural Ensemble Search via Bayesian Sampling.</a> <br>
		Yao Shu, Yizhou Chen, <b>Zhongxiang Dai</b> and Kian Hsiang Low. <br>
<!--		In <i>38th Conference on Uncertainty in Artificial Intelligence (<b>UAI-22</b>) </i>  <br> 
-->
		<i>UAI 2022</i>. Acceptance rate: 32.3%. [<a href="https://openreview.net/forum?id=Bh4lBPUjqg9">OpenReview</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> Neural architecture search, neural ensemble search.
-->
		</p>
		</li>
		<li>
		<p>
		<a href="https://openreview.net/forum?id=v-v1cpNNK_v">NASI: Label- and Data-agnostic Neural Architecture Search at Initialization.</a> <br>
		Yao Shu, Shaofeng Cai, <b>Zhongxiang Dai</b>, Beng Chin Ooi and Kian Hsiang Low. <br> 
<!--		In <i>10th International Conference on Learning Representations (<b>ICLR-22</b>) </i>  <br> 
-->
		<i>ICLR 2022</i>. Acceptance rate: 32.3%. [<a href="https://openreview.net/forum?id=v-v1cpNNK_v">OpenReview</a>, <a href="https://arxiv.org/abs/2109.00817">arXiv</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> training-free neural architecture search, neural tangent kernel.
-->
		</p>
		</li>
<!--
	</ul>

	<h3>
	2021
	</h3>
	<ul>
-->
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/dp_fbo.pdf">Differentially Private Federated Bayesian Optimization with Distributed Exploration.</a> <br>
		<b>Zhongxiang Dai</b>, Kian Hsiang Low and Patrick Jaillet. <br> 
<!--		In <i>35th Conference on Neural Information Processing Systems (<b>NeurIPS-21</b>)</i>, Dec 6-14, 2021. <br> 
-->
		<i>NeurIPS 2021</i>. Acceptance rate: 26%. [<a href="https://openreview.net/forum?id=OdsuC3H1WQ3">OpenReview</a>, <a href="https://github.com/daizhongxiang/Differentially-Private-Federated-Bayesian-Optimization">Code</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> federated hyperparameter tuning, differential privacy, federated Bayesian optimization.
-->
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/CVaR_BO.pdf">Optimizing Conditional Value-At-Risk of Black-Box Functions.</a> <br>
		Quoc Phong Nguyen, <b>Zhongxiang Dai</b>, Kian Hsiang Low and Patrick Jaillet. <br> 
<!--		In <i>35th Conference on Neural Information Processing Systems (<b>NeurIPS-21</b>)</i>, Dec 6-14, 2021. <br> 
-->
		<i>NeurIPS 2021</i>. Acceptance rate: 26%. [<a href="https://openreview.net/forum?id=Tc6Uk03Te7g">OpenReview</a>, <a href="https://github.com/qphong/BayesOpt-LV">Code</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> conditional value-at-risk, risk-averse optimization.
-->
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/frl.pdf">Fault-Tolerant Federated Reinforcement Learning with Theoretical Guarantee.</a> <br>
		Xiaofeng Fan, Yining Ma, <b>Zhongxiang Dai</b>, Wei Jing, Cheston Tan and Kian Hsiang Low. <br> 
<!--		In <i>35th Conference on Neural Information Processing Systems (<b>NeurIPS-21</b>)</i>, Dec 6-14, 2021. <br>
-->
		<i>NeurIPS 2021</i>. Acceptance rate: 26%. [<a href="https://openreview.net/forum?id=ospGnpuf6L">OpenReview</a>, <a href="https://github.com/flint-xf-fan/Byzantine-Federeated-RL">Code</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> federated reinforcement learning, byzantine optimization, policy gradient.
-->
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/VaR_BO.pdf">Value-at-Risk Optimization with Gaussian Processes.</a> <br>
		Quoc Phong Nguyen, <b>Zhongxiang Dai</b>, Kian Hsiang Low and Patrick Jaillet. <br> 
<!--		In <i>38th International Conference on Machine Learning (<b>ICML-21</b>),</i> Jun 18-24, 2021. <br>
-->
		<i>ICML 2021</i>. Acceptance rate: 21.4%. [<a href="http://proceedings.mlr.press/v139/nguyen21b/nguyen21b.pdf">Proceedings</a>, <a href="https://github.com/qphong/BayesOpt-LV">Code</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> value-at-risk, risk-averse optimization.
-->
		</p>
		</li>
<!--
	</ul>
	<h3>
	2020
	</h3>
	<ul>
-->
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/fbo.pdf">Federated Bayesian Optimization via Thompson Sampling.</a> <br>
		<b>Zhongxiang Dai</b>, Kian Hsiang Low and Patrick Jaillet. <br> 
<!--		In <i>34th Conference on Neural Information Processing Systems (<b>NeurIPS-20</b>)</i>, Dec 6-12, 2020. <br> 
-->
		<i>NeurIPS 2020</i>. Acceptance rate: 20.1%. [<a href="https://github.com/daizhongxiang/Federated_Bayesian_Optimization">Code</a>, <a href="https://papers.nips.cc/paper/2020/hash/6dfe08eda761bd321f8a9b239f6f4ec3-Abstract.html">Proceedings</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> Bayesian optimization, federated learning, Thompson sampling.
-->
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/R2_B2.pdf">R2-B2: Recursive Reasoning-Based Bayesian Optimization for No-Regret Learning in Games.</a> <br>
		<b>Zhongxiang Dai</b>, Yizhou Chen, Kian Hsiang Low, Patrick Jaillet and Teck-Hua Ho. <br> 
<!--		In <i>37th International Conference on Machine Learning (<b>ICML-20</b>)</i>, Jul 12-18, 2020. <br> 
-->
		<i>ICML 2020</i>. Acceptance rate: 21.8%. [<a href="https://github.com/daizhongxiang/R2-B2">Code</a>, <a href="https://proceedings.icml.cc/paper/2020/hash/a6e38981ecdd65fe9dcdfcd8d1f58f05-Abstract.html">Proceedings</a>, <a href="https://slideslive.com/38928476/r2b2-recursive-reasoningbased-bayesian-optimization-for-noregret-learning-in-games?ref=speaker-17344-latest">Video</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> Bayesian optimization, adversarial machine learning, multi-agent reinforcement learning, game theory.
-->
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/private_bo.pdf"> Private Outsourced Bayesian Optimization.</a> <br>
		Dmitrii Kharkovskii, <b>Zhongxiang Dai</b> and Kian Hsiang Low. <br> 
<!--		In <i>37th International Conference on Machine Learning (<b>ICML-20</b>)</i>, Jul 12-18, 2020. <br> 
-->
		<i>ICML 2020</i>. Acceptance rate: 21.8%. [<a href="https://github.com/Mitan/po-gp-ucb">Code</a>, <a href="https://proceedings.icml.cc/paper/2020/hash/3487596cf54cb393afddaa965714ab1f-Abstract.html">Proceedings</a>, <a href="https://slideslive.com/38928513/private-outsourced-bayesian-optimization?ref=speaker-17344-latest">Video</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> Bayesian optimization, differential privacy.
-->
		</p>
		</li>
<!--
	</ul>
	<h3>
	2019
	</h3>
	<ul>
-->
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/bo_bos.pdf">Bayesian Optimization Meets Bayesian Optimal Stopping.</a> <br>
		<b>Zhongxiang Dai</b>, Haibin Yu, Kian Hsiang Low, and Patrick Jaillet. <br> 
<!--		In <i>36th International Conference on Machine Learning (<b>ICML-19</b>)</i>, Long Beach, CA, Jun 9-15, 2019. <br> 
-->
		<i>ICML 2019</i>. Acceptance rate: 22.6%. [<a href="https://github.com/daizhongxiang/Bayesian-Optimization-Meets-Bayesian-Optimal-Stopping">Code</a>, <a href="http://proceedings.mlr.press/v97/dai19a.html">Proceedings</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> Bayesian optimization, early stopping, multi-fidelity, reinforcement learning, feature selection.
-->
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/uai2019.pdf">Bayesian Optimization with Binary Auxiliary Information.</a> <br>
		Yehong Zhang, <b>Zhongxiang Dai</b>, and Kian Hsiang Low. <br>
<!--		In <i>Conference on Uncertainty in Artificial Intelligence (<b>UAI-19</b>) </i>, Tel Aviv, Israel, Jul 22-25, 2019. <br>
-->
		<i>UAI 2019</i>. Acceptance rate: 26.2% (plenary talk). [<a href="https://github.com/YehongZ/MixedTypeBO">Code</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> Bayesian optimization, multi-fidelity, entropy search, reinforcement learning.
-->
		</p>
		</li>
		<li>
		<p>
		<a href="https://daizhongxiang.github.io/papers/nips2019.pdf">Implicit Posterior Variational Inference for Deep Gaussian Processes.</a> <br>
		Haibin Yu*, Yizhou Chen*, <b>Zhongxiang Dai</b>, Kian Hsiang Low, and Patrick Jaillet. <br> 
<!--		In <i>33th Conference on Neural Information Processing Systems (<b>NeurIPS-19</b>)</i>. Vancouver, Canada, Dec 7 - 12, 2019. <br>
-->
		<i>NeurIPS 2019</i>. Acceptance rate: 3% (spotlight). [<a href="https://github.com/HeroKillerEver/ipvi-dgp">Code</a>] <br>
<!--		<span style="color:#9F000F"><i>Key Words:</i></span> deep Gaussian processes, generative adversarial networks, game theory.
-->
		</p>
		</li>
	</ol>
	
	<!--	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
	-->

	<!--	
	<h3>
	Previous Publications on Computational Neuroscience
	</h3>
	<ul>
		<li>
		<p>
		<a href="https://www.sciencedirect.com/science/article/pii/S2352289520300217">Stress-induced Changes in Modular Organizations of Human Brain Functional Networks.</a> <br>
		Yuan Zhang, <b>Zhongxiang Dai</b>, Jianping Hu, Shaozheng Qin, Rongjun Yu, and Yu Sun. <br>
		<i>Neurobiology of Stress, 2020</i>.
		</p>
		</li>
		<li>
		<p>
		<a href="https://link.springer.com/article/10.1007/s11682-018-9935-8">Altered Intra and Inter-hemispheric Functional Dysconnectivity in Schizophrenia.</a> <br>
		Yuan Zhang, <b>Zhongxiang Dai</b>, Yu Chen, Kang Sim, Yu Sun, and Rongjun Yu. <br>
		<i>Brain Imaging and Behavior, 2018</i>.
		</p>
		</li>
		<li>
		<p>
		<a href="https://ieeexplore.ieee.org/abstract/document/8254390/authors#authors"> Functional Connectivity Analysis of Mental Fatigue Reveals Different Network Topological Alterations Between Driving and Vigilance Tasks.</a> <br>
		Georgios N. Dimitrakopoulos, Ioannis Kakkos, <b>Zhongxiang Dai</b>, Hongtao Wang, Kyriakos Sgarbas, Nitish Thakor, Anastasios Bezerianos, and Yu Sun <br>
		<i>IEEE Transactions on Neural Systems and Rehabilitation Engineering, 2018</i>
		</p>
		</li>
		<li>
		<p>
		<a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23501">Modular Level Alterations of Structure Function Coupling in Schizophrenia Connectome.</a> <br>
		Yu Sun, <b>Zhongxiang Dai</b>, Junhua Li, Simon L. Collinson, and Kang Sim. <br>
		<i>Human Brain Mapping, 2017</i>.
		</p>
		</li>
		<li>
		<p>
		<a href="https://www.sciencedirect.com/science/article/pii/S1053811917301969">The Effects of A Mid-task Break on the Brain Connectome in Healthy Participants: A Resting-state Functional MRI Study.</a> <br>
		Yu Sun*, Julian Lim*, <b>Zhongxiang Dai</b>, KianFoong Wong, Fumihiko Taya, Yu Chen, Junhua Li,
		Nitish Thakor, and Anastasios Bezerianos. <br> 
		<i>NeuroImage, 2017</i>.
		</p>
		</li>
		<li>
		<p>
		<a href="https://www.frontiersin.org/articles/10.3389/fnhum.2017.00237/full">EEG Cortical Connectivity Analysis of Working Memory Reveals Topological Reorganization in Theta and Alpha Bands.</a> <br>
		<b>Zhongxiang Dai</b>, Joshua De Souza, Julian Lim, Paul M. Ho, Yu Chen, Junhua Li, Nitish Thakor,
Anastasios Bezerianos, and Yu Sun. <br> 
		<i>Frontiers in Human Neuroscience, 2017</i>.
		</p>
		</li>
		<li>
		<p>
		<a href="https://ieeexplore.ieee.org/document/7919266">Task-independent Mental Workload Classification Based upon Common Multiband EEG Cortical Connectivity.</a> <br>
		Georgios N. Dimitrakopoulos*, Ioannis Kakkos*, <b>Zhongxiang Dai</b>, Julian Lim, Anastasios Bezerianos, and Yu Sun. <br> 
		<i>IEEE Transactions on Neural Systems and Rehabilitation Engineering, 2017</i>
		</p>
		</li>
		<li>
		<p>
		<a href="https://www.nature.com/articles/srep34291">Temporal Efficiency Evaluation and Small-worldness Characterization in Temporal Networks.</a> <br>
		<b>Zhongxiang Dai</b>, Yu Chen, Junhua Li, Johnson Fam, Anastasios Bezerianos, and Yu Sun. <br>
		<i>Scientific Reports, 2016</i>.
		</p>
		</li>
	</ul>
	-->
            </td>
			</tr>
        </tbody></table>		




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Awards and Honors</heading>
	<ul>
		<li>
		<p>
		<a href="https://www.comp.nus.edu.sg/news/2021-dean-s-graduate-research-excellence-award/">Dean's Graduate Research Excellence Award</a>, NUS, School of Computing, 2021
		</p>
		</li>
		<li>
		<p>
		Research Achievement Award × 2, NUS, School of Computing, 2019 & 2020
		</p>
		</li>
		<li>
		<p>
		Singapore-MIT Alliance for Research and Technology (SMART) <a href="https://smart.mit.edu/fellowships/for-graduates-smart-graduates">Graduate Fellowship</a>, Aug 2017
		</p>
		</li>
	<!-- 	<li>
		<p>
		JDDiscovery Population Dynamics Census and Prediction Competition 2018 (annual competition hosted by JD.com): <i>global champion</i>,
ranked 1st among > 2,100 teams, Jan 2019 (<a href="https://www.comp.nus.edu.sg/news/3096-2019-jdd-2018-challenge/">News in English</a>, <a href="https://mp.weixin.qq.com/s/khoLVJ2YjJsvkutEBIDGmg">News in Chinese</a>)
		</p>
		</li> -->
		<li>
		<p>
		ST Electronics Prize × 2 (<i>the top student in the cohort</i> of Electrical Engineering Year 1 & 2, NUS), Academic Year
2011/2012 & 2012/2013
		</p>
		</li>
		<li>
		<p>
		Dean’s List × 5 (top 5% in Electrical Engineering, NUS), 2011-2015
		</p>
		</li>
		<!-- <li>
		<p>
		Singapore Ministry of Education SM3 scholarship for undergraduate PRC students, 2010
		</p>
		</li> -->
	</ul>
            </td>
          </tr>
        </tbody></table>		


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Professional Services</heading>
	<ul>
<!--		<li>
		Senior Program Committee (SPC) member of ICML 2022
		</li>
	-->
		<li>
		Senior Program Committee (SPC) member of IJCAI 2021, Program Committee Board member of IJCAI 2022-2024
		</li>
		<li>
		Program Committee (PC) member/reviewer of
		</li>
		<ul>
			<li>
			ICML (2021, 2022, 2023, 2024)
			</li>
			<li>
			NeurIPS (2020, 2021, 2022, 2023, 2024)
			</li>
			<li>
			ICLR (2021, 2022, 2023)
			</li>
			<li>
			UAI (2023)
			</li>
			<li>
			AISTATS (2023)
			</li>
			<li>
			AAAI (2021, 2022, 2023)
			</li>
			<li>
			CoRL (2020, 2021, 2022)
			</li>
			<li>
			CVPR (2021, 2022)
			</li>
			<li>
			ICCV (2021)
			</li>
			<li>
			AAMAS (2023)
			</li>
			<li>
			IROS (2021)
			</li>
			<li>
			ICRA (2022)
			</li>
		</ul>
<!--		<li>
		External reviewer for IJCAI 2020.
		</li>
-->
		<li>
		Journal reviewer for
		</li>
		<ul>
			<li>
			IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)
			</li>
			<li>
			Operations Research
			</li>			
			<li>
			SIAM Journal on Optimization
			</li>			
			<li>
			Automatica
			</li>
			<li>
			Transactions on Machine Learning Research (TMLR)
  		</li>
			<li>
			Neural Networks
			</li>
			<li>
			IEEE Robotics and Automation Letters (RA-L)
			</li>
		</ul>
	</ul>
            </td>
          </tr>
        </tbody></table>		


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Academic Talks</heading>
	<ul>
		<li>
		<i>Differentially Private Federated Bayesian Optimization with Distributed Exploration</i>, at <a href="https://ncript.comp.nus.edu.sg/site/ncript-workshop-2023/">N-CRiPT Technical Workshop</a>, Apr 20, 2023.
		</li>
		<li>
		<i>Bayesian Optimization Meets Bayesian Optimal Stopping</i>, at Singapore-MIT Alliance, Future Urban Mobility Symposium 2019, Jan 28, 2019.
		</li>
<!-- 		<li>
		<i>Bayesian Optimization Meets Bayesian Optimal Stopping</i>, at Learning and Vision Lab Group Seminar, NUS, ECE, Mar 8, 2019.
		</li>
		<li>
		<i>R2-B2: Recursive Reasoning-Based Bayesian Optimization for No-Regret Learning in Games</i>, at NUS Computing Research Week 2020, Aug 4, 2020 (<i>top 3 student presenter</i>).
		</li> -->
	</ul>
            </td>
          </tr>
        </tbody></table>		


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Teaching</heading>
	<ul>
		<li>
		Tutor for <i>CS3244 Machine Learning</i>, NUS School of Computing (Spring 2019)
		</li>
		<li>
		Teaching Assistant for <i>CS1010E Programming Methodology</i>, NUS School of Computing (3 semesters from 2012 to 2014)
		</li>
	</ul>
            </td>
          </tr>
        </tbody></table>		


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
                Website borrowed from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
  
	<a href="https://info.flagcounter.com/5tZn"><img src="https://s01.flagcounter.com/count2/5tZn/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_1/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
</body>

</html>
